{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.initializers import normal\n",
    "from keras.utils import plot_model\n",
    "from deap import base, creator, tools, algorithms\n",
    "from deap.benchmarks.tools import diversity, convergence, hypervolume\n",
    "from functools import partial\n",
    "import numpy as np\n",
    "import random\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(n_layers, input_dim, neurons, activation='sigmoid', initializer=None):\n",
    "    if isinstance(neurons, list):\n",
    "        assert len(neurons) == n_layers\n",
    "    else:\n",
    "        neurons = [neurons] * n_layers\n",
    "        \n",
    "    if initializer is None:\n",
    "        # Uses normal initializer\n",
    "        initializer = normal(mean=0, stddev=0.1, seed=13)\n",
    "        \n",
    "    model = Sequential()\n",
    "    \n",
    "    # Adds first hidden layer with input_dim parameter\n",
    "    model.add(Dense(units=neurons[0], \n",
    "                    input_dim=input_dim, \n",
    "                    activation=activation,\n",
    "                    kernel_initializer=initializer, \n",
    "                    name='hidden_layer'))\n",
    "    \n",
    "    \n",
    "    # Adds output layer\n",
    "    model.add(Dense(units=2, activation=activation, kernel_initializer=initializer, name='net_output'))\n",
    "    \n",
    "    # Compiles the model\n",
    "    model.compile(loss='mean_squared_error', optimizer='Adam', metrics=['mean_squared_error'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dim = 7\n",
    "x_train = np.random.random((1000, data_dim))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# randomly sellect one array\n",
    "x_train[np.random.randint(x_train.shape[0], size=1), :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/richban/.local/share/virtualenvs/behavioral.neuroevolution-ViNSkuNA/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "model = build_model(n_layers=1, input_dim=7, neurons=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind = np.concatenate(tuple(weight.flatten() for weight in model.get_weights())).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind[50:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuple(weight.flatten() for weight in model.get_weights())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(model).__name__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot model graph\n",
    "plot_model(model, show_shapes=True, show_layer_names=True, to_file='model.png')\n",
    "from IPython.display import Image\n",
    "Image(retina=True, filename='model.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict(x_train[np.random.randint(x_train.shape[0], size=1), :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict(x_train[np.random.randint(x_train.shape[0], size=1), :])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.get_weights()[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.get_weights()[2].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = np.concatenate(\n",
    "                (\n",
    "                    model.get_weights()[0].flatten(),\n",
    "                    model.get_weights()[2].flatten()\n",
    "                )\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights[:35].reshape((7, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights[-10:].reshape((5, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.get_weights()[2].flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.get_layer(name='hidden_layer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# including the bias weights\n",
    "for l in model.layers:\n",
    "    print(l.get_config())\n",
    "    print(l.get_weights())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "creator.create(\"FitnessMax\", base.Fitness, weights=(1.0, 1.0))\n",
    "creator.create(\"Individual\", list, fitness=creator.FitnessMax, model=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initIndividual(cls, model):\n",
    "    weights = [np.random.permutation(w.flat).reshape(w.shape) for w in model.get_weights()]\n",
    "    return cls(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "toolbox = base.Toolbox()\n",
    "toolbox.register(\"individual\", initIndividual, creator.Individual, model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind1 = toolbox.individual()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind1.fitness.values = (1.0, 1.1)\n",
    "print(ind1.fitness)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mutant = toolbox.clone(ind1)\n",
    "ind2, = tools.mutGaussian(mutant, mu=0.0, sigma=0.2, indpb=0.2)\n",
    "del mutant.fitness.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mutateIndividual(individual):\n",
    "    mutant = toolbox.clone(ind1)\n",
    "    mutated_ind = [tools.mutGaussian(weight, mu=0.0, sigma=0.2, indpb=0.9) for weight in mutant]\n",
    "    del mutant.fitness.values\n",
    "    return mutated_ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mutateIndividual(ind1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "toolbox.register(\"population\", tools.initRepeat, list, toolbox.individual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pop = toolbox.population(n=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pop[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pop[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_function(model, chromosome):\n",
    "    x_data = np.random.random((1, 8))\n",
    "    net_output = model.predict(x_data)[0]\n",
    "    return (net_output[0]*np.random.random_sample(), net_output[1]*np.random.random_sample(),)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mutate_individual(individual):\n",
    "    for i, weight in enumerate(individual):\n",
    "        w, = tools.mutFlipBit(weight.flatten(), indpb=0.3)\n",
    "        individual[i] = w.reshape(weight.shape)\n",
    "    return individual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mate_individuals(ind1, ind2):\n",
    "    for i, (w1, w2) in enumerate(zip(ind1, ind2)):\n",
    "        cx1, cx2 = tools.cxTwoPoint(w1.flatten(), w2.flatten())\n",
    "        ind1[i], ind2[i] = cx1.reshape(w1.shape), cx2.reshape(w2.shape)\n",
    "    return ind1, ind2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Multiobjective optmization\"\"\"\n",
    "model = build_model(1, 8, 5)\n",
    "# Creating the appropriate type of the problem\n",
    "creator.create(\"FitnessMax\", base.Fitness, weights=(1.0, 1.0))\n",
    "creator.create(\"Individual\", list,\n",
    "               fitness=creator.FitnessMax, model=None)\n",
    "\n",
    "def initIndividual(cls, model):\n",
    "    weights = [np.random.permutation(w.flat).reshape(\n",
    "        w.shape) for w in model.get_weights()]\n",
    "    return cls(weights)\n",
    "\n",
    "toolbox = base.Toolbox()\n",
    "history = tools.History()\n",
    "toolbox.register(\"individual\", initIndividual,\n",
    "                 creator.Individual, model=model)\n",
    "\n",
    " # register the crossover operator\n",
    "toolbox.register('mate', mate_individuals)\n",
    "# register the mutation operator\n",
    "toolbox.register('mutate', mutate_individual)\n",
    "# register the evaluation function\n",
    "toolbox.register('evaluate', partial(eval_function, model))\n",
    "# register NSGA-II multiobjective optimization algorithm\n",
    "toolbox.register(\"select\", tools.selNSGA2)\n",
    " # instantiate the population\n",
    "toolbox.register('population', tools.initRepeat,\n",
    "                 list, toolbox.individual)\n",
    "\n",
    "# maintain stats of the evolution\n",
    "stats = tools.Statistics(lambda ind: ind.fitness.values)\n",
    "stats.register('avg', np.mean)\n",
    "stats.register('std', np.std)\n",
    "stats.register('min', np.min)\n",
    "stats.register('max', np.max)\n",
    "\n",
    "logbook = tools.Logbook()\n",
    "logbook.header = \"gen\", \"evals\", \"std\", \"min\", \"avg\", \"max\"\n",
    "\n",
    "# create an initial population of N individuals\n",
    "pop = toolbox.population(n=20)\n",
    "history.update(pop)\n",
    "\n",
    "def eq(ind1, ind2):\n",
    "    return np.array_equal(ind1[0], ind2[0])\n",
    "    \n",
    "\n",
    "# object that contain the best individuals\n",
    "hof = tools.ParetoFront(eq)\n",
    "\n",
    "# Evaluate the individuals with an invalid fitness\n",
    "invalid_ind = [ind for ind in pop if not ind.fitness.valid]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fitnesses = toolbox.map(toolbox.evaluate, invalid_ind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ind, fit in zip(invalid_ind, fitnesses):\n",
    "        ind.fitness.values = fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is just to assign the crowding distance to the individuals\n",
    "# no actual selection is done\n",
    "pop = toolbox.select(pop, len(pop))\n",
    "\n",
    "record = stats.compile(pop)\n",
    "logbook.record(gen=0, evals=len(invalid_ind), **record)\n",
    "print(logbook.stream)\n",
    "hof.update(pop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_inds, best_inds_fitness = [], []\n",
    "\n",
    "# Begin the generational process\n",
    "for gen in range(1, 21):\n",
    "    # Vary the population\n",
    "    offspring = tools.selTournamentDCD(pop, len(pop))\n",
    "    offspring = [toolbox.clone(ind) for ind in offspring]\n",
    "\n",
    "    for ind1, ind2 in zip(offspring[::2], offspring[1::2]):\n",
    "        if random.random() <= 0.9:\n",
    "            toolbox.mate(ind1, ind2)\n",
    "\n",
    "        toolbox.mutate(ind1)\n",
    "        toolbox.mutate(ind2)\n",
    "        del ind1.fitness.values, ind2.fitness.values\n",
    "\n",
    "    # Evaluate the individuals with an invalid fitness\n",
    "    invalid_ind = [ind for ind in offspring if not ind.fitness.valid]\n",
    "    fitnesses = toolbox.map(toolbox.evaluate, invalid_ind)\n",
    "    for ind, fit in zip(invalid_ind, fitnesses):\n",
    "        ind.fitness.values = fit\n",
    "    \n",
    "    best_ind = tools.selBest(pop, 1)[0]\n",
    "    best_inds.append(best_ind) # add the best individual for each generation\n",
    "    best_inds_fitness.append(best_ind.fitness.values)\n",
    "\n",
    "    # Select the next generation population\n",
    "    pop = toolbox.select(pop + offspring, len(offspring))\n",
    "    record = stats.compile(pop)\n",
    "    logbook.record(gen=gen, evals=len(invalid_ind), **record)\n",
    "    hof.update(pop)\n",
    "    \n",
    "print(\"Final population hypervolume is %f\" % hypervolume(pop, [11.0, 11.0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(logbook.stream)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "offspring = tools.selTournamentDCD(pop, len(pop))\n",
    "offspring = [toolbox.clone(ind) for ind in offspring]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind1 = offspring[0]\n",
    "ind2 = offspring[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mate_individuals(ind1, ind2):\n",
    "    for i, w1, w2 in enumerate(zip(ind1, ind2)):\n",
    "        cx1, cx2 = tools.cxTwoPoint(w1.flatten(), w2.flatten())\n",
    "        ind1[i], ind2[i] = cx1.reshape(w1.shape), cx2.reshape(w2.shape)\n",
    "    return ind1, ind2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind1, ind2 = mate_individuals(ind1, ind2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(ind2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind1 = mutate_individual(ind1, 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind1.history_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "toolbox.mate(ind1, ind2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind1.__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = np.array([[0.25773812, 0.99876807, 0.98062046, 0.16666008, 0.19844747,\n",
    "        0.85773822, 0.13071776],]).reshape((7,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.array([0.25773812, 0.99876807, 0.98062046, 0.16666008, 0.19844747, 0.85773822, 0.13071776])\n",
    "data = data.reshape((1, 7))\n",
    "print(data.shape)\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_individual(cls, model):\n",
    "    ind = cls(np.concatenate(\n",
    "        (\n",
    "            model.get_weights()[0].flatten(),\n",
    "            model.get_weights()[2].flatten()\n",
    "        )\n",
    "    ))\n",
    "\n",
    "    ind.shape_1 = model.get_weights()[0].shape\n",
    "    ind.shape_2 = model.get_weights()[2].shape\n",
    "\n",
    "    return ind\n",
    "\n",
    "# Creating the appropriate type of the problem\n",
    "creator.create(\"FitnessMax\", base.Fitness, weights=(1.0, 1.0))\n",
    "creator.create(\"Individual\", np.ndarray,\n",
    "               fitness=creator.FitnessMax, model=None)\n",
    "\n",
    "toolbox = base.Toolbox()\n",
    "history = tools.History()\n",
    "\n",
    "toolbox.register(\"individual\", init_individual,\n",
    "                 creator.Individual, model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind1 = toolbox.individual()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind1.__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind1.__class__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Ind(object): \n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind = Ind()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "setattr(ind, 'weights', [tuple(weights.shape) for weights in model.get_weights()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind.weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genome = list(np.concatenate(tuple(weight.flatten() for weight in model.get_weights())).tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[(tuple(weights.shape), len(weights.flatten())) for weights in model.get_weights()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = [\n",
    "    np.array(genome[:35]).reshape(ind.weights[0]),\n",
    "    np.array(genome[35:40]).reshape(ind.weights[1]),\n",
    "    np.array(genome[40:50]).reshape(ind.weights[2]),\n",
    "    np.array(genome[-2:]).reshape(ind.weights[3]),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genome[35:40]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genome[-3:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('data/neat/2019-06-05/best_genomes.pkl', 'rb') as f:\n",
    "    genome = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_individual(cls, model):\n",
    "    \"\"\"Concatenated weights of the Keras model\n",
    "    Weights are concatenated into a single list of floating points.\n",
    "    The weights than are reshaped and adjusted in the eval_function in\n",
    "    order to update the model weights correctly.\n",
    "    \"\"\"\n",
    "    ind = cls(np.concatenate(tuple(weight.flatten()\n",
    "                                   for weight in model.get_weights())).tolist())\n",
    "    ind.weights_shape = [tuple(weights.shape)\n",
    "                         for weights in model.get_weights()]\n",
    "    ind.features = None\n",
    "    ind.weights = None\n",
    "    ind.str_disparity = None\n",
    "    ind.diversity = None\n",
    "    ind.task_fitness = None\n",
    "    ind.evaluation = None\n",
    "    ind.position = None\n",
    "    ind.gen = None\n",
    "    ind.key = None\n",
    "\n",
    "    return ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the appropriate type of the problem\n",
    "creator.create(\"FitnessMax\", base.Fitness, weights=(1.0, -1.0, 1.0))\n",
    "creator.create(\"Individual\", list, fitness=creator.FitnessMax, model=None)\n",
    "toolbox = base.Toolbox()\n",
    "toolbox.register(\"individual\", init_individual, creator.Individual, model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind = toolbox.individual()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind.key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind.weights_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del ind.features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(ind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    " \n",
    "# load model\n",
    "model = load_model('data/results/transferability_simulation_4/keras_models/218_model.h5')\n",
    "# summarize model.\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_individual(cls, model, size, imin, imax):\n",
    "    \"\"\"Concatenated weights of the Keras model\n",
    "    Weights are concatenated into a single list of floating points.\n",
    "    The weights than are reshaped and adjusted in the eval_function in\n",
    "    order to update the model weights correctly.\n",
    "    \"\"\"\n",
    "    ind = cls(random.uniform(imin, imax) for _ in range(size))\n",
    "    ind.weights_shape = [tuple(weights.shape)\n",
    "                         for weights in model.get_weights()]\n",
    "    ind.features = None\n",
    "    ind.weights = None\n",
    "    ind.str_disparity = None\n",
    "    ind.diversity = None\n",
    "    ind.task_fitness = None\n",
    "    ind.evaluation = None\n",
    "    ind.position = None\n",
    "    ind.gen = None\n",
    "    ind.key = None\n",
    "\n",
    "    return ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "creator.create(\"FitnessMax\", base.Fitness, weights=(1.0, -1.0, 1.0))\n",
    "creator.create(\"Individual\", list,\n",
    "               fitness=creator.FitnessMax, model=None)\n",
    "\n",
    "toolbox = base.Toolbox()\n",
    "history = tools.History()\n",
    "\n",
    "SIZE = np.concatenate(tuple(weight.flatten()\n",
    "                            for weight in model.get_weights())).tolist()\n",
    "WEIGHTS_MIN = -1.0\n",
    "WEIGHTS_MAX = 1.0\n",
    "\n",
    "# Attribute generator random\n",
    "toolbox.register(\"individual\", init_individual,\n",
    "                 creator.Individual, model, len(SIZE), WEIGHTS_MIN, WEIGHTS_MAX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind = toolbox.individual()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind.features = np.array([0.6458, 0.0000, 1.0000,0.0000, 0.0000])\n",
    "ind.weights = model.get_weights()\n",
    "ind.str_disparity = 2.3\n",
    "ind.diversity = 1.03\n",
    "ind.task_fitness = 43.43\n",
    "ind.evaluation = 'thymio'\n",
    "ind.position = np.array([[0.2391, 0.1895], [0.2368,0.1887],[0.2338,0.1888]])\n",
    "ind.gen = 1\n",
    "ind.key = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('pickletest', 'wb') as fp:\n",
    "    pickle.dump(ind, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "ndividual = creator.Individual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/neat/2019-06-12/deap_inds/1_genome_.pkl', 'rb') as f:\n",
    "    genome = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
