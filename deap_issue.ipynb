{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.initializers import normal\n",
    "from keras.utils import plot_model\n",
    "from deap import base, creator, tools, algorithms\n",
    "from deap.benchmarks.tools import diversity, convergence, hypervolume\n",
    "from functools import partial\n",
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(n_layers, input_dim, neurons, activation='sigmoid', initializer=None):\n",
    "    if isinstance(neurons, list):\n",
    "        assert len(neurons) == n_layers\n",
    "    else:\n",
    "        neurons = [neurons] * n_layers\n",
    "        \n",
    "    if initializer is None:\n",
    "        # Uses normal initializer\n",
    "        initializer = normal(mean=0, stddev=0.1, seed=13)\n",
    "        \n",
    "    model = Sequential()\n",
    "    \n",
    "    # Adds first hidden layer with input_dim parameter\n",
    "    model.add(Dense(units=neurons[0], \n",
    "                    input_dim=input_dim, \n",
    "                    activation=activation,\n",
    "                    kernel_initializer=initializer, \n",
    "                    name='hidden_layer'))\n",
    "    \n",
    "    \n",
    "    # Adds output layer\n",
    "    model.add(Dense(units=2, activation=activation, kernel_initializer=initializer, name='net_output'))\n",
    "    \n",
    "    # Compiles the model\n",
    "    model.compile(loss='mean_squared_error', optimizer='Adam', metrics=['mean_squared_error'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/richban/.local/share/virtualenvs/behavioral.neuroevolution-ViNSkuNA/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "model = build_model(n_layers=1, input_dim=7, neurons=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_function(model, chromosome):\n",
    "    x_data = np.random.random((1, 7))\n",
    "    net_output = model.predict(x_data)[0]\n",
    "    return (net_output[0]*np.random.random_sample(), net_output[1]*np.random.random_sample(),)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gen\tevals\tstd     \tmin       \tavg    \tmax     \n",
      "0  \t20   \t0.150455\t0.00213751\t0.27826\t0.499812\n",
      "1  \t20   \t0.148792\t0.00213751\t0.340318\t0.499812\n",
      "2  \t20   \t0.14902 \t0.00213751\t0.348065\t0.499812\n",
      "3  \t20   \t0.150344\t0.00213751\t0.356254\t0.499812\n",
      "4  \t20   \t0.144813\t0.00213751\t0.371361\t0.499812\n",
      "5  \t20   \t0.111353\t0.00721352\t0.397109\t0.499812\n",
      "6  \t20   \t0.142861\t0.00721352\t0.379489\t0.503717\n",
      "7  \t20   \t0.140688\t0.00721352\t0.381588\t0.503717\n",
      "8  \t20   \t0.128579\t0.0179155 \t0.388223\t0.503717\n",
      "9  \t20   \t0.127695\t0.0179155 \t0.389502\t0.503717\n",
      "10 \t20   \t0.129663\t0.0179155 \t0.387579\t0.503717\n",
      "11 \t20   \t0.141915\t0.0179155 \t0.380596\t0.503717\n",
      "12 \t20   \t0.139106\t0.0179155 \t0.383908\t0.503717\n",
      "13 \t20   \t0.139106\t0.0179155 \t0.383908\t0.503717\n",
      "14 \t20   \t0.139031\t0.0179155 \t0.38522 \t0.503717\n",
      "15 \t20   \t0.14644 \t0.0179155 \t0.379111\t0.503717\n",
      "16 \t20   \t0.151957\t0.0179155 \t0.372729\t0.503717\n",
      "17 \t20   \t0.151957\t0.0179155 \t0.372729\t0.503717\n",
      "18 \t20   \t0.145917\t0.0179155 \t0.378183\t0.503717\n",
      "19 \t20   \t0.145917\t0.0179155 \t0.378183\t0.503717\n",
      "20 \t20   \t0.147472\t0.0179155 \t0.377749\t0.503717\n"
     ]
    }
   ],
   "source": [
    "def init_individual(cls, model):\n",
    "    ind = cls(np.concatenate(\n",
    "        (\n",
    "            model.get_weights()[0].flatten(),\n",
    "            model.get_weights()[2].flatten()\n",
    "        )\n",
    "    ).tolist())\n",
    "\n",
    "    ind.shape_1 = model.get_weights()[0].shape\n",
    "    ind.shape_2 = model.get_weights()[2].shape\n",
    "    ind.features = None\n",
    "    ind.weights = None\n",
    "\n",
    "    return ind\n",
    "\n",
    "CXPB = 0.9\n",
    "N_GEN = 20\n",
    "POP = 20\n",
    "\n",
    "# Creating the appropriate type of the problem\n",
    "creator.create(\"FitnessMax\", base.Fitness, weights=(1.0, 1.0))\n",
    "creator.create(\"Individual\", list,\n",
    "               fitness=creator.FitnessMax, model=None)\n",
    "\n",
    "toolbox = base.Toolbox()\n",
    "history = tools.History()\n",
    "\n",
    "toolbox.register(\"individual\", init_individual,\n",
    "                 creator.Individual, model=model)\n",
    "\n",
    "# register the crossover operator\n",
    "toolbox.register('mate', tools.cxTwoPoint)\n",
    "\n",
    "# register the mutation operator\n",
    "toolbox.register('mutate', tools.mutFlipBit, indpb=0.5)\n",
    "\n",
    "# register the evaluation function\n",
    "toolbox.register('evaluate', partial(eval_function, model))\n",
    "\n",
    "# register NSGA-II multiobjective optimization algorithm\n",
    "toolbox.register(\"select\", tools.selNSGA2)\n",
    "\n",
    "# instantiate the population\n",
    "toolbox.register('population', tools.initRepeat,\n",
    "                 list, toolbox.individual)\n",
    "\n",
    "# maintain stats of the evolution\n",
    "stats = tools.Statistics(lambda ind: ind.fitness.values)\n",
    "stats.register('avg', np.mean)\n",
    "stats.register('std', np.std)\n",
    "stats.register('min', np.min)\n",
    "stats.register('max', np.max)\n",
    "\n",
    "logbook = tools.Logbook()\n",
    "logbook.header = \"gen\", \"evals\", \"std\", \"min\", \"avg\", \"max\"\n",
    "\n",
    "# create an initial population of N individuals\n",
    "pop = toolbox.population(n=POP)\n",
    "history.update(pop)\n",
    "\n",
    "# object that contain the best individuals\n",
    "hof = tools.ParetoFront()\n",
    "\n",
    "# Evaluate the individuals with an invalid fitness\n",
    "invalid_ind = [ind for ind in pop if not ind.fitness.valid]\n",
    "fitnesses = toolbox.map(toolbox.evaluate, invalid_ind)\n",
    "\n",
    "for ind, fit in zip(invalid_ind, fitnesses):\n",
    "    ind.fitness.values = fit\n",
    "\n",
    "# This is just to assign the crowding distance to the individuals\n",
    "# no actual selection is done\n",
    "pop = toolbox.select(pop, len(pop))\n",
    "record = stats.compile(pop)\n",
    "logbook.record(gen=0, evals=len(invalid_ind), **record)\n",
    "print(logbook.stream)\n",
    "hof.update(pop)\n",
    "\n",
    "best_inds, best_inds_fitness = [], []\n",
    "\n",
    "# Begin the generational process\n",
    "for gen in range(1, N_GEN+1):\n",
    "    # Vary the population\n",
    "    offspring = tools.selTournamentDCD(pop, len(pop))\n",
    "    offspring = [toolbox.clone(ind) for ind in offspring]\n",
    "\n",
    "    for ind1, ind2 in zip(offspring[::2], offspring[1::2]):\n",
    "        if random.random() <= CXPB:\n",
    "            toolbox.mate(ind1, ind2)\n",
    "\n",
    "        toolbox.mutate(ind1)\n",
    "        toolbox.mutate(ind2)\n",
    "        del ind1.fitness.values, ind2.fitness.values\n",
    "\n",
    "    # Evaluate the individuals with an invalid fitness\n",
    "    invalid_ind = [ind for ind in offspring if not ind.fitness.valid]\n",
    "    fitnesses = toolbox.map(toolbox.evaluate, invalid_ind)\n",
    "    for ind, fit in zip(invalid_ind, fitnesses):\n",
    "        ind.fitness.values = fit\n",
    "\n",
    "    # add the best individual for each generation\n",
    "    best_ind = tools.selBest(pop, 1)[0]\n",
    "    best_inds.append(best_ind)\n",
    "    best_inds_fitness.append(best_ind.fitness.values)\n",
    "\n",
    "    # Select the next generation population\n",
    "    pop = toolbox.select(pop + offspring, len(offspring))\n",
    "    record = stats.compile(pop)\n",
    "    logbook.record(gen=gen, evals=len(invalid_ind), **record)\n",
    "    hof.update(pop)\n",
    "\n",
    "print(logbook.stream)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind = toolbox.individual()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fitness': deap.creator.FitnessMax(()),\n",
       " 'shape_1': (7, 5),\n",
       " 'shape_2': (5, 2),\n",
       " 'features': None,\n",
       " 'weights': None}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ind.__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.017451664432883263,\n",
       " -0.022578200325369835,\n",
       " 0.019674310460686684,\n",
       " 0.038747698068618774,\n",
       " 0.025138601660728455,\n",
       " 0.005156669765710831,\n",
       " -0.010682681575417519,\n",
       " -0.12614494562149048,\n",
       " -0.023369936272501945,\n",
       " -0.10256432741880417,\n",
       " -0.05181825906038284,\n",
       " -0.03860422968864441,\n",
       " -0.13391904532909393,\n",
       " -0.06569492071866989,\n",
       " 0.1440880447626114,\n",
       " 0.08051245659589767,\n",
       " 0.0773625299334526,\n",
       " 0.015084986574947834,\n",
       " 0.027785733342170715,\n",
       " -0.08993145823478699,\n",
       " 0.13227465748786926,\n",
       " 0.07975079864263535,\n",
       " 0.08298309892416,\n",
       " 0.015040106140077114,\n",
       " -0.09476090967655182,\n",
       " -0.0743572860956192,\n",
       " -0.006988647859543562,\n",
       " -0.06255804002285004,\n",
       " -0.1166984960436821,\n",
       " -0.01686728559434414,\n",
       " 0.06776601076126099,\n",
       " -0.0345042422413826,\n",
       " 0.17205838859081268,\n",
       " -0.02406460791826248,\n",
       " 0.039534296840429306,\n",
       " 0.017451664432883263,\n",
       " -0.022578200325369835,\n",
       " 0.019674310460686684,\n",
       " 0.038747698068618774,\n",
       " 0.025138601660728455,\n",
       " 0.005156669765710831,\n",
       " -0.010682681575417519,\n",
       " -0.12614494562149048,\n",
       " -0.023369936272501945,\n",
       " -0.10256432741880417]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
