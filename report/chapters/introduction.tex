\chapter{Introduction}

Evolutionary Robotics concerns with the use of Evolutionary Algorithms in robotics. The use of EA in robotics is motivated by a number of issues \cite{meyer1998evolutionary} \cite{grefenstette1994evolutionary}. One of the issues is concerned with the difficulties of hard-coding the control architecture of a robot that has to solve a given task in an unknown or possible changing environment. Because it's impossible to predict each problem that a robot might encounter in a constantly changing environment. More precisely, it's difficult to program a robot control system that can foresee every possible state of its environment and the action it should take.  Another issue is related to simulation models. Building pre-defined abstract models of the world is not sufficient in a continuously changing environment since these models often fail to reflect the complexities of the real world, such as light, gravity, noise, and errors in real sensors, actuators, etc. In response to such difficulties, researchers advocate the use of EA for the development of robots that can adapt and evolve behaviors based on specific environment and problems it's facing.

Evolutionary algorithms are indeed attractive optimization procedures to apply, that merely rewards each evaluated solution with a value that reflects its performance based on a fitness function. However, this procedure often requires a large number of evaluations before optimal solutions are found. As ER concerns robots, it should theoretically be evaluated on physical robot \cite{floreano1998evolutionary}. In practice, the optimization process on a physical robot can be very time-consuming. As a result, works that apply the optimization directly on the physical robot often evaluate few individuals along with a few generations, which reduces the competence of the evolutionary methods. For instance in \cite{faina2017automating}, controllers for a small tracked robot \textit{Pololu Zumo 32U4} \footnote{Pololu. Pololu Zumo 32u4 robot, 2016. \url{https://www.pololu.com/category/170/zumo-32u4-robot}} have been evolved with a population of 15 individuals during 20 generations and 2 simulations run, that is 600 evaluations during the entire optimization process. Adding to that the time of the actual evaluation of each controller resulted in 48 hours of running time.

For this reason, simulators in ER are often an appealing way to speed up the optimization process. Accurate simulation models are designed in order to evaluate the fitness in a fully virtual set-up. Accurate simulation models are designed in order to evaluate the fitness in a fully virtual set-up. Even though accurate models are build that corresponds to reality and successful controllers are evolved, the results are often sealed in the simulated world because of inaccuracies of the simulator or bad modeled of physical features in the simulator like friction, light, aerodynamics, etc. This transfer phenomenon is called \textit{reality gap}. Reality gap remains a critical issue that prevents the use of ER for practical applications in robotics. With my thesis I want to explore/compare state-of-the-art approaches to the \textit{reality gap} problem. In particular, the focus is on three main approaches:

\begin{enumerate}
    \item Reality-based optimization process where the entire optimization takes place fully on the physical robot.
    \item Simulation-based optimization process with the entire optimization in simulation.
    \item Robot in the loop optimization process, that optimize solutions in simulation but allows transfer experiments during the evolutionary process.
\end{enumerate}

Our first essential focus is on the robot in the loop optimization process, concretely the \textit{transferability approach} \cite{koos2012transferability} which is currently the best state-of-the-art approach to bypass the reality gap. However, instead of attempting to conduct as few transfers as possible, the \textit{transferability measure} is obtained for N solutions in every generation. We hypothesize that if the \textit{surrogate model} is more accurate and updated more frequently, this would allow boosting the evolutionary search. Another insight is concerned with an accurate simulation model, which is designed to accurately mimic the dynamics of the physical environment. Optimal solutions that emerge in simulation should transfer well onto the physical robot and achieve good performance/behavior in reality. In order to quantify how well a controller evolved in simulation transfer to reality, we define a \textit{transferable measure} which compares the corresponding real and simulated behavior.

Additionally, our Evolutionary strategy consists of two approaches. The first one is concerned with evolving weights of a feedforward neural network. In the second approach, instead of evolving just the weights of ANN controllers with a fixed structure we are also optimizing ANN controllers using NEAT \cite{stanley2002evolving}. A genetic algorithm for evolving both weights and topology of artificial neural networks.

All of the above approaches will be systematically compared and validated to on a robotic application, particularly obstacle avoidance task. As we need to evaluate a lot of controllers in the real world, which is time-consuming, we build an automated robotic platform which enables us to test and validate as many transfers as we want and run the entire optimization process on the physical robot without human intervention while taking the entire physical environment into account. Likewise, a simulation model will be designed from scratch that properly describes the dynamics of the real environment.

\section{Evolutionary Algorithms and Neuroevolution}

\emph{Evolutionary algorithms} focus on global optimization problems inspired by biological evolution. EA are population-based, metaheuristic search procedures that incorporate genetic operators. The algorithm maintains a population of candidate solutions which is subjected to natural selection and mutation \cite{back1996evolutionary}. In each generation, a set of offspring is generated by applying bio operators such as \emph{mutation, crossover, selection}. Each generation, the fitness of every individual in the population is evaluated. More fit individuals are stochastically selected from the current population, and each individual's \emph{genome} is modified (recombined or randomly mutated) to form a new generation. The algorithm terminates when either the maximum number of generations has been produced, or fitness level has been reached for the population. Within this method, a number of researches have successfully employed an evolutionary procedure, as evolutionary robotics is concerned \cite{salomon1999evolving} \cite{faina2017automating}.

\subsection{Multi-objective optimization}

Multi-objective optimization is concerned with optimization problems which involve several objective functions to be optimized simultaneously. For example, an objective for a problem may require to minimize cost while maximizing profits, thus these two contradicting objectives can't be optimized simultaneously. Maximizing one objective leads to weakening the other objective. Therefore there is no single feasible solution, but instead a set of \emph{Pareto} optimal solutions.  A solution is called \emph{non-dominated}, if none of the objective functions can be improved in value without degrading some of the other objective values \cite{deb2014multi}.

Joost Huizinga and Jeff Clune gave a good example \cite{Huizinga2018EvolvingMR} how multiobjetive challenges can emerge in robot training task, which has to be able to learn both to run and jump. In their hypothetical example their argue, that running is much easier to learn than jumping, but learning to jump well first is an important stepping stone in order to become excellent in both tasks. Therefore individuals who are better at running, are more favorable than individuals that are average at jumping, and those individuals who are good at jumping are not selected in the future generations. Figure \ref{fig:jumping_running}, an important stepping stone is lost during evolution.

To address this issue, they a designed \emph{Combinatorial Multi-Objective Evolutionary Algorithm (CMOEA)} in which the population selection method is applied by \emph{NSGA-II} with performance measure on the multiple tasks associated with as one objective and \emph{behavioral diversity} \cite{behavioraldiversity} as the other objective. It's implemented by measuring the distance of some behavioral features between each individual. They have successfully evolved a controller on a multimodal robotics problem with six subtasks.

This approach has been similarly applied in the \emph{Transferability Approach}. In order to tackle the trade-offs between efficiency and trasferability. Since solutions that performe the best in simulation, might exploit certain bad simulated phenomenas or bugs, making them not transferable, transferability and efficiency appear to be conflicting objectives \cite{koos2012transferability}. Their proposed optimization process employes multi-objetive evolutionary algorithm in which two objetives ared defined: a task-dependent fitness as one objective computed in simulation only and a transferability objective as the second objective. 

Evolutionary algorithm such as the Non-dominated sorting genetic algorithm II \gls{nsga2} \cite{deb200fast} is a standard approach in solving multi-objective optimization problem. The algorithm is similar to a classical evolutionary algorithm. However, the selection mechanism is different. The algorithm applies a Pareto-based ranking scheme. This means that a rank is assigned to each individual based on nondominance - individuals that are not dominated by another get the highest rank. Similarly, as in EA, parents produce a new offspring population using genetic operators (i.e. crossover and mutation).

\subsection{NeuroEvolution of Augmenting Topologies}

NeuroEvolution of Augmenting Topologies \gls{neat} \cite{stanley2002evolving} is a genetic algorithm for evolving both weights and topology of artificial neural networks. \gls{neat} starts with minimal ANN structure and grows incrementally, which ensures low dimensionality of the connection weights and therefore minimizes the search space. The main traits of NEAT are \emph{genetic encoding, competing convention, speciation}.

NEAT encode networks with direct encoding schemes. The genome contains a list of \emph{connection genes} and list of \emph{nodes genes} which appears in the phenotype. Node genes represent inputs, hidden nodes, and outputs that can be connected. Whether an in-node and out-node is connected is expressed in the \emph{connection gene}. Additionally each connection gene contains a \emph{innovation} number.

\section{The Reality Gap}

As mentioned before, the problem with optimization in simulations is that, the simulated agent and the environment are both abstract representations of the physical world. Even if accurate models are build and effective controllers are evolved, evolution might exploit certain properties of the simulation that are different or not present at all in reality. In this manner solutions with high fitness value might have completely different behaviors in reality. This disparity between simulation and reality is defined as the \emph{reality gap}.

In ER, there are three main types of approachces to address this issue:

\begin{enumerate}
    \item Reality-bazed optimization approaches where the optimization takes place, fully or partly, on the physical robot.
    \item Simulation-based optimization approaches with an entire optimization process in simulation.
    \item Robot-in-the-loop simulation-based optimiza- tion approaches, that fully optimize solutions in simulation, but 		  also allow few transfer experiments during the process.
\end{enumerate}

\subsection{Reality-based optimization}

Since the reality gap results from discrepancy between reality and simulation, some works attempt to deal with this problem by running the entire optimization process directly on the physical robot. In \cite{floreano1998evolutionary} experiments have been conducted on small miniature mobile robot Khepera \cite{mondada1999development} to solve a navigation task. The optimization took more than 60 hours with about 8000 evaluations on the physical robot for single run. Within a similiar approach, Jacobsen has explored the issue on automated reality-based optimization, furthemore the building and reconfiguration of test environments. Experiment on a navigation task took around 48 hours with 30 evaluations during the optimization process. As one can see, this optimization procedure are very time-consuming.

\subsection{Simulation-based optimization}

As a consequence of highly time-consuming optimization procedures on a physical robot, some researches attempt to deal with the reality gap problem by building accurate models with advanced simulation environments. However simulation models also introduce trade offs between accuracy and computational cost. Likewise they add to much overhead to be effectively used in experiments, as we have discoved later. As have been pointed out in \cite{mouret201720}, even more advanced and accurate models led to reality gap issues. Thus some techniques have been developed in order to evolve effective controllers in simulations that are less accurate but still robust enough to trasfer well onto the real robot. Among the simulation-based optimization the most formalized is Jakobi's approach \cite{jakobi1995noise}, in which a simulation model has to assimilate noise from real world. For instance, this approach has been successfully aplied to a wondering and obstacle-avoidance task for an octopod robot.

\subsection{Robot-in-the-loop simulation-based optimization}


\section{The Transferability Approach}
