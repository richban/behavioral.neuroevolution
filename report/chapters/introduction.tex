\chapter{Introduction}

Evolutionary Robotics concerns with the use of Evolutionary Algorithms in robotics. The use of EA in robotics is motivated by a number of issues \cite{meyer1998evolutionary} \cite{grefenstette1994evolutionary}. One of the issues is concerned with the difficulties of hard-coding the control architecture of a robot that has to solve a given task in an unknown or possible changing environment. Because it's impossible to predict each problem that a robot might encounter in a constantly changing environment. More precisely, it's difficult to program a robot control system that can foresee every possible state of its environment and the action it should take.  Another issue is related to simulation models. Building pre-defined abstract models of the world is not sufficient in a continuously changing environment since these models often fail to reflect the complexities of the real world, such as light, gravity, noise, and errors in real sensors, actuators, etc. In response to such difficulties, researchers advocate the use of EA for the development of robots that can adapt and evolve behaviors based on specific environment and problems it's facing.

Evolutionary algorithms are indeed attractive optimization procedures to apply, that merely rewards each evaluated solution with a value that reflects its performance based on a fitness function. However, this procedure often requires a large number of evaluations before optimal solutions are found. As ER concerns robots, it should theoretically be evaluated on physical robot \cite{floreano1998evolutionary}. In practice, the optimization process on a physical robot can be very time-consuming. As a result, works that apply the optimization directly on the physical robot often evaluate few individuals along with a few generations, which reduces the competence of the evolutionary methods. For instance in \cite{faina2017automating}, controllers for a small tracked robot \textit{Pololu Zumo 32U4} \footnote{Pololu. Pololu Zumo 32u4 robot, 2016. \url{https://www.pololu.com/category/170/zumo-32u4-robot}} have been evolved with a population of 15 individuals during 20 generations and 2 simulations run, that is 600 evaluations during the entire optimization process. Adding to that the time of the actual evaluation of each controller resulted in 48 hours of running time.

For this reason, simulators in ER are often an appealing way to speed up the optimization process. Accurate simulation models are designed in order to evaluate the fitness in a fully virtual set-up. Accurate simulation models are designed in order to evaluate the fitness in a fully virtual set-up. Even though accurate models are build that corresponds to reality and successful controllers are evolved, the results are often sealed in the simulated world because of inaccuracies of the simulator or bad modeled of physical features in the simulator like friction, light, aerodynamics, etc. This transfer phenomenon is called \textit{reality gap}. Reality gap remains a critical issue that prevents the use of ER for practical applications in robotics. With my thesis I want to explore/compare state-of-the-art approaches to the \textit{reality gap} problem. In particular, the focus is on three main approaches:

\begin{enumerate}
    \item Reality-based optimization process where the entire optimization takes place fully on the physical robot.
    \item Simulation-based optimization process with the entire optimization in simulation.
    \item Robot in the loop optimization process, that optimize solutions in simulation but allows transfer experiments during the evolutionary process.
\end{enumerate}

Our first essential focus is on the robot in the loop optimization process, concretely the \textit{transferability approach} \cite{koos2012transferability} which is currently the best state-of-the-art approach to bypass the reality gap. However, instead of attempting to conduct as few transfers as possible, the \textit{transferability measure} is obtained for N solutions in every generation. We hypothesize that if the \textit{surrogate model} is more accurate and updated more frequently, this would allow boosting the evolutionary search. Another insight is concerned with an accurate simulation model, which is designed to accurately mimic the dynamics of the physical environment. Optimal solutions that emerge in simulation should transfer well onto the physical robot and achieve good performance/behavior in reality. In order to quantify how well a controller evolved in simulation transfer to reality, we define a \textit{transferable measure} which compares the corresponding real and simulated behavior.

Additionally, our Evolutionary strategy consists of two approaches. The first one is concerned with evolving weights of a feedforward neural network. In the second approach, instead of evolving just the weights of ANN controllers with a fixed structure we are also optimizing ANN controllers using NEAT \cite{stanley2002evolving}. A genetic algorithm for evolving both weights and topology of artificial neural networks.

All of the above approaches will be systematically compared and validated to on a robotic application, particularly obstacle avoidance task. As we need to evaluate a lot of controllers in the real world, which is time-consuming, we build an automated robotic platform which enables us to test and validate as many transfers as we want and run the entire optimization process on the physical robot without human intervention while taking the entire physical environment into account. Likewise, a simulation model will be designed from scratch that properly describes the dynamics of the real environment.

\section{Evolutionary Algorithms and Neuroevolution}

\emph{Evolutionary algorithms} focus on global optimization problems inspired by biological evolution. EA are population-based, metaheuristic search procedures that incorporate genetic operators. The algorithm maintains a population of candidate solutions which is subjected to natural selection and mutation \cite{back1996evolutionary}. In each generation, a set of offspring is generated by applying bio operators such as \emph{mutation, crossover, selection}. Each generation, the fitness of every individual in the population is evaluated. More fit individuals are stochastically selected from the current population, and each individual's \emph{genome} is modified (recombined or randomly mutated) to form a new generation. The algorithm terminates when either the maximum number of generations has been produced, or fitness level has been reached for the population. Within this method, a number of researches have successfully employed an evolutionary procedure, as evolutionary robotics is concerned \cite{salomon1999evolving} \cite{faina2017automating}.

\subsection{Multi-objective optimization}

Multi-objective optimization is concerned with optimization problems which involve several objective functions to be optimized simultaneously. For example, an objective for a problem may require to minimize cost while maximizing profits, thus these two contradicting objectives can't be optimized simultaneously. Maximizing one objective leads to weakening the other objective. Therefore there is no single feasible solution, but instead a set of \emph{Pareto} optimal solutions.  A solution is called \emph{non-dominated}, if none of the objective functions can be improved in value without degrading some of the other objective values \cite{deb2014multi}.

Joost Huizinga and Jeff Clune gave a good example \cite{Huizinga2018EvolvingMR} how multiobjective challenges can emerge in robot training task, which has to be able to learn both to run and jump. In their hypothetical example their argue, that running is much easier to learn than jumping, but learning to jump well first is an important stepping stone in order to become excellent in both tasks. Therefore individuals who are better at running, are more favorable than individuals that are average at jumping, and those individuals who are good at jumping are not selected in the future generations.

To address this issue, they designed \emph{Combinatorial Multi-Objective Evolutionary Algorithm (CMOEA)} in which the population selection method is applied by \emph{NSGA-II} with performance measure on the multiple tasks associated with as one objective and \emph{behavioral diversity} \cite{behavioraldiversity} as the other objective. It's implemented by measuring the distance of some behavioral features between each individual. They have successfully evolved a controller on a multimodal robotics problem with six subtasks.

This approach has been similarly applied in the \emph{Transferability Approach}. In order to tackle the trade-offs between efficiency and transferability. Since solutions that perform the best in simulation, might exploit certain bad simulated phenomena or bugs, making them not transferable, transferability and efficiency appear to be conflicting objectives \cite{koos2012transferability}. Their proposed optimization process employes a multi-objective evolutionary algorithm in which two objectives are defined: a task-dependent fitness as one objective computed in simulation only and a transferability objective as the second objective. 

An evolutionary algorithm such as the Non-dominated sorting genetic algorithm II \gls{nsga2} \cite{deb200fast} is a standard approach in solving a multi-objective optimization problem. The algorithm is similar to a classical evolutionary algorithm. However, the selection mechanism is different. The algorithm applies a Pareto-based ranking scheme. This means that a rank is assigned to each individual based on nondominated - individuals that are not dominated by another get the highest rank. Similarly, as in EA, parents produce a new offspring population using genetic operators (i.e. crossover and mutation).

\subsection{NeuroEvolution of Augmenting Topologies}

NeuroEvolution of Augmenting Topologies \gls{neat} \cite{stanley2002evolving} is a genetic algorithm for evolving both weights and topology of artificial neural networks. \gls{neat} starts with minimal ANN structure and grows incrementally, which ensures low dimensionality of the connection weights and therefore minimizes the search space. The main traits of NEAT are \emph{genetic encoding, competing convention, speciation}.

NEAT encode networks with direct encoding schemes. The genome contains a list of \emph{connection genes} and list of \emph{nodes genes} which appears in the phenotype. Node genes represent inputs, hidden nodes, and outputs that can be connected. Whether an in-node and out-node are connected is expressed in the \emph{connection gene}. Additionally each connection gene contains a \emph{innovation} number.

\section{The Reality Gap}

As mentioned before, the problem with optimization in simulations is that the simulated agent and the environment are both abstract representations of the physical world. Even if accurate models are build and effective controllers are evolved, evolution might exploit certain properties of the simulation that are different or not present at all in reality. In this manner solutions with high fitness value might have completely different behaviors in reality. This disparity between simulation and reality is defined as the \emph{reality gap}.

In ER, there are three main types of approaches to address this issue:

\begin{enumerate}
    \item Reality-bazed optimization approaches where the optimization takes place, fully or partly, on the physical robot.
    \item Simulation-based optimization approaches with an entire optimization process in simulation.
    \item Robot-in-the-loop simulation-based optimization approaches, that fully optimize solutions in simulation, but also allow few transfer experiments during the process.
\end{enumerate}

\subsection{Reality-based optimization}

Since the reality gap results from a discrepancy between reality and simulation, some works attempt to deal with this problem by running the entire optimization process directly on the physical robot. In \cite{floreano1998evolutionary} experiments have been conducted on small miniature mobile robot Khepera \cite{mondada1999development} to solve a navigation task. The optimization took more than 60 hours with about 8000 evaluations on the physical robot for a single run. Within a similar approach, Jacobsen has explored the issue of automated reality-based optimization, furthermore the building and reconfiguration of test environments. Experiment on a navigation task took around 48 hours with 30 evaluations during the optimization process. As one can see, this optimization approach is very time-consuming.

\subsection{Simulation-based optimization}

As a consequence of highly time-consuming optimization procedures on a physical robot, some researches attempt to deal with the reality gap problem by building accurate models with advanced simulation environments. However, simulation models also introduce trade-offs between accuracy and computational cost. Likewise, they add too much overhead to be effectively used in experiments, as we have discovered later. As have been pointed out in \cite{mouret201720}, even more, advanced and accurate models led to reality gap issues. Thus some techniques have been developed in order to evolve effective controllers in simulations that are less accurate but still robust enough to transfer well onto the real robot. Among the simulation-based optimization, the most formalized is Jakobi's approach \cite{jakobi1995noise}, in which a simulation model has to assimilate noise from the real world. For instance, this approach has been successfully applied to a wondering and obstacle-avoidance task for an octopod robot \cite{jakobi1998running}.

\subsection{Robot-in-the-loop simulation-based optimization}

The robot-in-the-loop simulation-based optimization approaches also rely mostly on simulators but some transfer experiments are allowed during the optimization \cite{inproceedings}. Essentially, this approach involves optimization mainly in simulation but few transfers are allowed during the optimization process to conduct some meaningful results on the real robot. This allows to guide the evolutionary search and reduce the number of experiments required to find optimal solutions. There are several works who successfully implemented this approach \cite{bongard2006resilient} \cite{koos2009automatic} but the most promising approach is the s so-called \emph{transferability approach}, which is able to learn the limits of the simulation and select individuals with good fitness in simulation and with a high probability of transferability.

\section{The Transferability Approach}

\section{Concluding thoughts}

As mentioned earlier, the aim of the thesis project is to compare and explore state-of-the-art approaches to the reality gap problem. After reviewing the various approaches, we defined the following experiments and approaches to tackle the reality-gap problem:

\begin{enumerate}
    \item{\emph{Simulation-based optimization}. In this approach, we first aim to evolve an obstacle avoidance behavior in simulation. Afterwards, we take the best controllers among the simulation runs and look at how well they transfer to reality. Since we rely on a highly accurate simulator and the task is somehow simple, optimal solutions that emerge in simulation should transfer well into reality. Although we hypothesize that's not guaranteed. This experiment involves optimizing ANN controllers using NEAT.}
    
    \item{\emph{Reality-based optimization}. Although the optimization on a physical robot is time-consuming, it's an appealing approach to explore. Likewise the previous approach, this experiment involves evolving obstacle avoidance behavior using the same evolutionary strategy - NEAT. Moreover, as far as evolutionary robotics is concerned, controllers are always evolved for a specific robot, therefore we look how evolved behaviors differ when transferred to a different but same model of \emph{Thymio} robot.}
    
    \item{\emph{Robot-in-the-loop simulation-based optimization}. More precisely, the \emph{Transferability approach} will be reproduced, which relies on multi-objective optimization with a pareto-based ranking scheme. Again, our  hypothesis is based on the fact that if the \textit{surrogate model} is more accurate and updated more frequently, this would lead to more transferable controllers since in the original implementation the average number of transferred controllers is 6 for each run.}
    
    \item{Since much of the experiments involves reality-based optimization and validation on the physical robot, it is clear to investigage how to aid and speed up the optimization/evaluation process which has been forsaken in much of the works. To address this issue, we build an automated robotic platform which enables us to test and validate as many transfers as we want and run the entire optimization process on the physical robot without human intervention while taking the entire physical environment into account.}
\end{enumerate}




